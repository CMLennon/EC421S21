options(htmltools.dir.version = FALSE)
library(pacman)
p_load(
broom, latex2exp, ggplot2, ggthemes, viridis, extrafont,
dplyr,
magrittr, knitr, parallel
)
# Define pink color
red_pink <- "#e64173"
grey_light <- "grey70"
grey_mid <- "grey50"
grey_dark <- "grey20"
# Dark slate grey: #314f4f
# Notes directory
dir_slides <- "~/Dropbox/UO/Teaching/EC421W19/LectureNotes/02Review/"
# Knitr options
opts_chunk$set(
comment = "#>",
fig.align = "center",
fig.height = 7,
fig.width = 10.5,
warning = F,
message = F
)
# A blank theme for ggplot
theme_empty <- theme_bw() + theme(
line = element_blank(),
rect = element_blank(),
strip.text = element_blank(),
axis.text = element_blank(),
plot.title = element_blank(),
axis.title = element_blank(),
plot.margin = structure(c(0, 0, -0.5, -1), unit = "lines", valid.unit = 3L, class = "unit"),
legend.position = "none"
)
theme_simple <- theme_bw() + theme(
line = element_blank(),
panel.grid = element_blank(),
rect = element_blank(),
strip.text = element_blank(),
axis.text.x = element_text(size = 18, family = "STIXGeneral"),
axis.text.y = element_blank(),
axis.ticks = element_blank(),
plot.title = element_blank(),
axis.title = element_blank(),
# plot.margin = structure(c(0, 0, -1, -1), unit = "lines", valid.unit = 3L, class = "unit"),
legend.position = "none"
)
theme_axes_math <- theme_void() + theme(
text = element_text(family = "MathJax_Math"),
axis.title = element_text(size = 22),
axis.title.x = element_text(hjust = .95, margin = margin(0.15, 0, 0, 0, unit = "lines")),
axis.title.y = element_text(vjust = .95, margin = margin(0, 0.15, 0, 0, unit = "lines")),
axis.line = element_line(
color = "grey70",
size = 0.25,
arrow = arrow(angle = 30, length = unit(0.15, "inches")
)),
plot.margin = structure(c(1, 0, 1, 0), unit = "lines", valid.unit = 3L, class = "unit"),
legend.position = "none"
)
theme_axes_serif <- theme_void() + theme(
text = element_text(family = "MathJax_Main"),
axis.title = element_text(size = 22),
axis.title.x = element_text(hjust = .95, margin = margin(0.15, 0, 0, 0, unit = "lines")),
axis.title.y = element_text(vjust = .95, margin = margin(0, 0.15, 0, 0, unit = "lines")),
axis.line = element_line(
color = "grey70",
size = 0.25,
arrow = arrow(angle = 30, length = unit(0.15, "inches")
)),
plot.margin = structure(c(1, 0, 1, 0), unit = "lines", valid.unit = 3L, class = "unit"),
legend.position = "none"
)
theme_axes <- theme_void() + theme(
text = element_text(family = "Fira Sans Book"),
axis.title = element_text(size = 18),
axis.title.x = element_text(hjust = .95, margin = margin(0.15, 0, 0, 0, unit = "lines")),
axis.title.y = element_text(vjust = .95, margin = margin(0, 0.15, 0, 0, unit = "lines")),
axis.line = element_line(
color = grey_light,
size = 0.25,
arrow = arrow(angle = 30, length = unit(0.15, "inches")
)),
plot.margin = structure(c(1, 0, 1, 0), unit = "lines", valid.unit = 3L, class = "unit"),
legend.position = "none"
)
pagedown::chrome_print(
input = "/Heteroskedasticity.html",
timeout = 6000
)
pagedown::chrome_print(
input = "Heteroskedasticity.html",
timeout = 6000
)
p_load(sn)
rpoisson(1000,lambda =4)
rpois(1000,lambda =4)
20 - rpois(1000,lambda =4)
16 - rpois(1000,lambda =4) +rpois(1000,lambda = 2)
# Setup ----------------------------------------------------------------------------------
# Load packages, read full data
library(pacman)
p_load(tidyverse, readxl, haven, data.table, broom, magrittr, here, ipumsr)
ddi <- read_ipums_ddi("PS1_data/usa_00005.xml")
data <- read_ipums_micro(ddi)
#softmax function to find percentage weighting scheme with no distributional assumptions
data %<>% mutate(perwt_nrm = (PERWT - min(PERWT))/max(PERWT),perwt_sftmx= exp(perwt_nrm)/sum(exp(perwt_nrm))) %>% filter(AGE > 23)
# Load data ------------------------------------------------------------------------------
# Load ACS data
acs_raw = data
names(acs_raw) = tolower(names(acs_raw))
# Grab variable labels
var_desc = lapply(acs_raw, function(x) attributes(x)$label)
# Load ERS data
ers_raw = here("PS1_data/ers-rural-urban-2013.xls") %>% read_xls(sheet = 1)
# Load ERS data
ers_raw = "/Users/connor/Desktop/GithubProjects/Econometrics/EC421/Spring2021/PS-001/PS1_data/ers-rural-urban-2013.xls" %>% read_xls(sheet = 1)
# Data work: Prep ERS data ---------------------------------------------------------------
# Grab and name desired columns
ers_clean = transmute(
ers_raw,
fips = FIPS,
i_urban = 1 * (RUCC_2013 <= 5)
)
setDT(ers_clean)
# Data work: upsample rural weights
setDT(acs_raw)
acs_raw[, `:=`(fips = paste0(str_pad(statefip, 2, "left", 0), str_pad(countyfip, 3, "left", 0)))]
acs_raw = merge(
x = ers_clean,
y = acs_raw,
by = "fips",
all.x = F,
all.y = T
)
# Fix missingness from small areas (assuming rural)
acs_raw[is.na(i_urban), i_urban := .5]
acs_raw[, `:=`(perwt_sftmx = perwt_sftmx+(i_urban*-sd(acs_raw$perwt_sftmx)))]
acs_raw[i_urban == .5, i_urban := 0]
ddi <- read_ipums_ddi("PS1_data/usa_00005.xml")
ddi <- read_ipums_ddi("/Users/connor/Desktop/GithubProjects/Econometrics/EC421/Spring2021/PS-001/PS1_data/usa_00005.xml")
data <- read_ipums_micro(ddi)
ddi <- read_ipums_ddi("/Users/connor/Desktop/GithubProjects/Econometrics/EC421/Spring2021/PS-001/PS1_data/usa_00005.xml")
data <- read_ipums_micro(ddi)
#softmax function to find percentage weighting scheme with no distributional assumptions
data %<>% mutate(perwt_nrm = (PERWT - min(PERWT))/max(PERWT),perwt_sftmx= exp(perwt_nrm)/sum(exp(perwt_nrm))) %>% filter(AGE > 23)
# Load data ------------------------------------------------------------------------------
# Load ACS data
acs_raw = data
names(acs_raw) = tolower(names(acs_raw))
# Grab variable labels
var_desc = lapply(acs_raw, function(x) attributes(x)$label)
# Load ERS data
ers_raw = "/Users/connor/Desktop/GithubProjects/Econometrics/EC421/Spring2021/PS-001/PS1_data/ers-rural-urban-2013.xls" %>% read_xls(sheet = 1)
# Data work: Prep ERS data ---------------------------------------------------------------
# Grab and name desired columns
ers_clean = transmute(
ers_raw,
fips = FIPS,
i_urban = 1 * (RUCC_2013 <= 5)
)
setDT(ers_clean)
# Data work: upsample rural weights
setDT(acs_raw)
acs_raw[, `:=`(fips = paste0(str_pad(statefip, 2, "left", 0), str_pad(countyfip, 3, "left", 0)))]
acs_raw = merge(
x = ers_clean,
y = acs_raw,
by = "fips",
all.x = F,
all.y = T
)
# Fix missingness from small areas (assuming rural)
acs_raw[is.na(i_urban), i_urban := .5]
acs_raw[, `:=`(perwt_sftmx = perwt_sftmx+(i_urban*-sd(acs_raw$perwt_sftmx)))]
acs_raw[i_urban == .5, i_urban := 0]
# Data work: Clean ACS data --------------------------------------------------------------
# Convert data into data table
# Subset to individuals with non-zero commute times
# Change depart and arrive time to minutes past midnight
acs_raw[, `:=`(
time_depart = str_pad(departs, 4, "left", 0),
time_arrive = str_pad(arrives, 4, "left", 0)
)]
acs_raw[, `:=`(
time_depart =
as.numeric(str_sub(time_depart, 1, 2)) * 60 + as.numeric(str_sub(time_depart, 3, 4)),
time_arrive =
as.numeric(str_sub(time_arrive, 1, 2)) * 60 + as.numeric(str_sub(time_arrive, 3, 4))
)]
# Drop observations that arrive before they depart
# NOTE: Includes people right around midnight
acs_raw %<>% .[time_arrive - time_depart > 0]
# Indicators for race and sex
acs_clean = acs_raw[, .(
fips = paste0(str_pad(statefip, 2, "left", 0), str_pad(countyfip, 3, "left", 0)),
educ = educ,
age = age,
i_urban = i_urban,
i_citizen = 1*(citizen %in% c(0,1,2)),
i_noenglish = 1*(speakeng %in% c(1,6)),
i_only_english = 1*(speakeng == 3),
i_drive_to_work = 1*(tranwork %in% c(10:15, 20, 38)),
i_asian = 1 * (race %in% 4:6),
i_black = 1 * (race == 2),
i_indigenous = 1 * (race == 3),
i_white = 1 * (race == 1),
i_female = 1 * (sex == 2),
i_male = 1 * (sex == 1),
i_grad_college = 1 * (educd %in% c(101,114,115,116)),
i_grad_highschool = 1*(educd >= 62),
i_married = 1 * (marst %in% c(1:2)),
i_married_mult = 1 * (marrno %in% c(2:6)),
personal_income = ifelse(inctot != 9999999, inctot, NA) / 1e4,
i_health_insurance = 1 * (hcovany == 2),
i_internet = fcase(
cinethh %in% c(1,2), 1,
cinethh == 3, 0
),
time_depart,
time_arrive,
time_commuting = time_arrive - time_depart,
weights = perwt_sftmx
)]
acs_raw %<>% .[time_arrive - time_depart > 0]
# Indicators for race and sex
acs_clean = acs_raw[, .(
fips = paste0(str_pad(statefip, 2, "left", 0), str_pad(countyfip, 3, "left", 0)),
educ = educ,
marrno = marrno,
age = age,
i_urban = i_urban,
i_citizen = 1*(citizen %in% c(0,1,2)),
i_noenglish = 1*(speakeng %in% c(1,6)),
i_only_english = 1*(speakeng == 3),
i_drive_to_work = 1*(tranwork %in% c(10:15, 20, 38)),
i_asian = 1 * (race %in% 4:6),
i_black = 1 * (race == 2),
i_indigenous = 1 * (race == 3),
i_white = 1 * (race == 1),
i_female = 1 * (sex == 2),
i_male = 1 * (sex == 1),
i_grad_college = 1 * (educd %in% c(101,114,115,116)),
i_grad_highschool = 1*(educd >= 62),
i_married = 1 * (marst %in% c(1:2)),
i_married_mult = 1 * (marrno %in% c(2:6)),
personal_income = ifelse(inctot != 9999999, inctot, NA) / 1e4,
i_health_insurance = 1 * (hcovany == 2),
i_internet = fcase(
cinethh %in% c(1,2), 1,
cinethh == 3, 0
),
time_depart,
time_arrive,
time_commuting = time_arrive - time_depart,
weights = perwt_sftmx
)]
# Restrict to individuals with positive income (for logs in assignment)
acs_clean %<>% .[personal_income > 0]
# Data work: Join, sample, and clean -----------------------------------------------------
acs_sub = sample_n(acs_clean, size = 8000, weight = weights)
acs_sub[, fips := fips %>% str_sub(1, 2)]
setnames(acs_sub, old = "fips", new = "state_fips")
fips_xwalk = maps::state.fips %>% transmute(
state_fips = fips %>% str_pad(2, "left", 0),
state = abb
) %>% unique() %>% setDT()
acs_sub = merge(
x = fips_xwalk,
y = acs_sub,
by = "state_fips",
all.x = F,
all.y = T
)
acs_sub[, state_fips := NULL]
#save data
readr::write_rds(
acs_sub,
"ps-002-data.rds"
)
readr::write_csv(
acs_sub,
"ps-002-data.csv"
)
#run a regression of fitted values on your residual variable
error_reg = lm(l_resid ~ est17$fitted.values)
#retrieve residuals, square them then take log of those values to get log(u_i-squared)
l_resid = log(est17$residuals^2)
#model
est17 = lm(
personal_income ~ education + i_citizen + education:i_citizen + marrno + i_female + i_female:education,
data = ps_df
)
# Load dataset
ps_df = here("ps-002-data.csv") %>% read_csv()
# Load packages
library(pacman)
p_load(tidyverse, broom, skimr, here)
# Load dataset
ps_df = here("ps-002-data.csv") %>% read_csv()
#### ALTERNATIVELY
ps_df = here("ps-002-data.rds") %>% read_rds()
#model
est17 = lm(
personal_income ~ education + i_citizen + education:i_citizen + marrno + i_female + i_female:education,
data = ps_df
)
# The results
summary(est17)
#retrieve residuals, square them then take log of those values to get log(u_i-squared)
l_resid = log(est17$residuals^2)
#run a regression of fitted values on your residual variable
error_reg = lm(l_resid ~ est17$fitted.values)
#extract fitted values - exponentiate them
fitted_values = error_reg$fitted.values^2
#find logged u-squared
fitted
#create weights
weight = 1/fitted_values
#retrieve residuals, square them then take log of those values to get log(u_i-squared)
l_resid = log(est17$residuals^2)
#run a regression of fitted values on your residual variable
error_reg = lm(l_resid ~ est17$fitted.values)
#extract fitted values - exponentiate them
fitted_values = exp(error_reg$fitted.values)
#create weights
weight = 1/fitted_values
wls_est = lm(personal_income ~ education + i_citizen + education:i_citizen + marrno + i_female + i_female:education, weights = weight, data = ps_df)
wls_est %>% tidy()
weight
wls_est = lm(personal_income ~ education + i_citizen + education:i_citizen + marrno + i_female + i_female:education, weights = weight, data = ps_df)
wls_est %>% summary()
wls_est = lm(personal_income ~ education + i_citizen + education:i_citizen + marrno + i_female + i_female:education, weights = sqrt(weight), data = ps_df)
wls_est %>% summary()
wls_est = lm(personal_income ~ education + i_citizen + education:i_citizen + marrno + i_female + i_female:education + i_female:education:citizen, weights = sqrt(weight), data = ps_df)
wls_est = lm(personal_income ~ education + i_citizen + education:i_citizen + marrno + i_female + i_female:education + i_female:education:i_citizen, weights = sqrt(weight), data = ps_df)
wls_est %>% summary()
wls_est = lm(personal_income ~ education + i_citizen + education:i_citizen + marrno + i_female + i_female:education + i_female:education:i_citizen + i_female:i_citizen, weights = sqrt(weight), data = ps_df)
wls_est %>% summary()
#model
est17 = lm(
personal_income ~ education + i_citizen + education:i_citizen + marrno + i_female + i_female:education + i_female:education:i_citizen + i_female:i_citizen,
data = ps_df
)
# The results
summary(est17)
ps_df
#model
est17 = lm(
personal_income ~ education + i_citizen + marrno + i_female + i_female:education,
data = ps_df
)
# The results
summary(est17)
#model
est17 = lm(
personal_income ~ education + i_citizen + marrno + i_female + i_female:education + i_citizen:education,
data = ps_df
)
# The results
summary(est17)
#retrieve residuals, square them then take log of those values to get log(u_i-squared)
l_resid = log(est17$residuals^2)
#run a regression of fitted values on your residual variable
error_reg = lm(l_resid ~ est17$fitted.values)
#extract fitted values - exponentiate them
fitted_values = exp(error_reg$fitted.values)
#create weights
weight = 1/fitted_values
wls_est = lm(personal_income ~ education + i_citizen + marrno + i_female + i_female:education + i_citizen:education, weights = sqrt(weight), data = ps_df)
wls_est %>% summary()
#retrieve residuals, square them then take log of those values to get log(u_i-squared)
l_resid = log(est17$residuals^2)
#run a regression of fitted values on your residual variable
error_reg = lm(l_resid ~ est17$fitted.values + est17$fitted.values^2)
#extract fitted values - exponentiate them
fitted_values = exp(error_reg$fitted.values)
#create weights
weight = 1/fitted_values
wls_est = lm(personal_income ~ education + i_citizen + marrno + i_female + i_female:education + i_citizen:education, weights = sqrt(weight), data = ps_df)
wls_est %>% summary()
ggplot(
data = data.frame(
fitted = wls_est$fitted.values,
residual = wls_est$residuals
),
aes(x =fitted, y = residual)
) +
geom_point(size = 2.5, alpha = 0.4) +
xlab("WLS Fitted Values") +
ylab("WLS Residual") +
theme_minimal()
#retrieve residuals, square them then take log of those values to get log(u_i-squared)
l_resid = log(est17$residuals^2)
#run a regression of fitted values on your residual variable
error_reg = lm(l_resid ~ est17$fitted.values)
#extract fitted values - exponentiate them
fitted_values = exp(error_reg$fitted.values)
#create weights
weight = 1/fitted_values
#retrieve residuals, square them then take log of those values to get log(u_i-squared)
l_resid = log(est17$residuals^2)
fit = est17$fitted.values
#run a regression of fitted values on your residual variable
error_reg = lm(l_resid ~ fit)
#extract fitted values - exponentiate them
fitted_values = exp(error_reg$fitted.values)
#create weights
weight = 1/fitted_values
#retrieve residuals, square them then take log of those values to get log(u_i-squared)
l_resid = log(est17$residuals^2)
fit = est17$fitted.values
#run a regression of fitted values on your residual variable
error_reg = lm(l_resid ~ fit)
#extract fitted values - exponentiate them
fitted_values = exp(error_reg$fitted.values)
#create weights
weight = 1/fitted_values
#retrieve residuals, square them then take log of those values to get log(u_i-squared)
l_resid = log(est17$residuals^2)
fit = est17$fitted.values
#run a regression of fitted values on your residual variable
error_reg = lm(l_resid ~ fit)
#extract fitted values - exponentiate them
fitted_values = exp(error_reg$fitted.values)
#create weights
weight = 1/sqrt(fitted_values)
wls_est = lm(personal_income ~ education + i_citizen + marrno + i_female + i_female:education + i_citizen:education, weights = sqrt(weight), data = ps_df)
wls_est %>% summary()
ggplot(
data = data.frame(
fitted = wls_est$fitted.values,
residual = wls_est$residuals
),
aes(x =fitted, y = residual)
) +
geom_point(size = 2.5, alpha = 0.4) +
xlab("WLS Fitted Values") +
ylab("WLS Residual") +
theme_minimal()
